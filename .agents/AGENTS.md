# ðŸš¨ DO NOT MODIFY THIS FILE UNLESS SPECIFICALLY INSTRUCTED

## TL;DR
- Clarify if confidence < 80% or ambiguity exists; propose options
- Prefer simplicity, reuse existing patterns, and cite evidence with sources
- Use explicit uncertainty: prefix claims with "I'M UNCERTAIN ABOUT THIS:" and output "UNKNOWN" when unverifiable
- Solve only the stated problem; avoid over-engineering and premature optimization
- Verify with checks (simplicity, performance, maintainability, scope) before coding

---

## âš ï¸ 1. AI Behavior Guardrails & Anti-Patterns

**ðŸ”’ CRITICAL RULES â€” Read These First:**

**âš¡ Clarification Rule**
- When requirements or scope are ambiguous, or your confidence is below 80%, pause and ask a clarifying question before proceeding.

**âš¡ Explicit Uncertainty Rule**
- If not completely certain about a specific claim, prepend "I'M UNCERTAIN ABOUT THIS:" before that claim.
- Do not soften or omit this marker.
- When information is insufficient or unverifiable, output "UNKNOWN" explicitlyâ€”never fabricate plausible-sounding details.
- State confidence levels for factual claims as percentages (see ðŸ§  Confidence & Clarification Framework).
- Example: I'M UNCERTAIN ABOUT THIS: The component may need to handle the loading state differently.

**âš¡ Neutral Reasoning Guard**
- If information is uncertain or unverifiable, output "UNKNOWN" explicitly. Never invent details.
- Preserve coherence before completion.
- Meaning preservation is priority one.

### Common Failure Patterns & Root Causes

#### 1. Task Misinterpretation
- **Pattern:** Implementing features when asked to investigate/document
- **Root Cause:** Not carefully parsing the actual request
- **Prevention:** Explicit request type classification and scope analysis; confirm by asking a clarifying question when needed
- **Example:** Creating code when asked for a task document

#### 2. The Rush to Code
- **Pattern:** Jumping directly to implementation without proper analysis
- **Root Cause:** Overconfidence in understanding the problem
- **Prevention:** Analyze request thoroughly â†’ Verify understanding (ask for clarification if needed) â†’ Choose simplest approach
- **Example:** Asked to investigate, but starts changing code immediately

#### 3. Assumption-Based Changes
- **Pattern:** Modifying code based on assumptions rather than evidence
- **Root Cause:** Not reading existing implementation thoroughly
- **Prevention:** Require full code trace before any modifications; ask clarifying questions to resolve ambiguity
- **Example:** "Fixing" React state management that wasn't actually broken

#### 4. Cascading Breaks
- **Pattern:** "Fixing" non-existent problems and breaking working code
- **Root Cause:** Not testing assumptions before making changes
- **Prevention:** Verify problem exists through reproduction first; if reproduction is blocked by ambiguity, ask for clarification
- **Example:** Breaking working code by "fixing" non-existent problems

#### 5. Over-Engineering
- **Pattern:** Adding unnecessary complexity, abstractions, or "future-proofing"
- **Root Cause:** Anticipating needs that don't exist; gold-plating solutions
- **Prevention:** Solve ONLY the stated problem; reject premature optimization; confirm scope via a clarifying question when in doubt
- **Example:** Creating a complex state management system when useState suffices

---

## ðŸ§  2. CONFIDENCE & CLARIFICATION FRAMEWORK

**Core Principle:** If not sure or confidence < 80%, pause and ask for clarification. Present a multiple-choice path forward.

### Thresholds & actions

- **80â€“100:** Proceed.
- **40â€“79:** Proceed with caution. List assumptions/guardrails; test thoroughly and request a quick check.
- **0â€“39:** Ask for clarification with a multiple-choice question.
- **Safety override:** If there's a blocker or conflicting instruction, ask regardless of score.

**Confidence Gates:**
- Scale interpretation: 0â€“39% LOW | 40â€“79% MEDIUM | 80â€“100% HIGH
- If any core claim <40%: Mark "UNKNOWN" or request sources before proceeding
- If 40â€“79%: Provide caveats and counter-evidence; proceed with caution posture
- If â‰¥80%: Require at least one citable source or strong evidence-based justification

### Confidence scoring (0â€“100%)

**Weighted for TypeScript/React/Raycast code:**
- Requirements & acceptance criteria clarity â€” 25
- Component API contracts (props, state, effects, hooks) â€” 15
- Data flow & state management (React hooks, LocalStorage, yabai integration) â€” 15
- Type safety & data contracts (interfaces, type guards, validation) â€” 10
- Performance constraints (rendering, debouncing, caching, query optimization) â€” 10
- Integration with Raycast API & yabai CLI â€” 10
- Testing strategy (unit, integration, mocking) â€” 10
- Risk/impact to existing features (breaking changes, UX impact) â€” 5

Compute confidence as the weighted sum of factor scores (0â€“1). Round to a whole percent.

**Example calculation:**

Request: "Add minimize window action"
- Requirements clear (25/25) + Component API known (15/15) + Data flow simple (10/15) + Types clear (10/10) + Perf OK (10/10) + Yabai command unknown (0/10) + Testing ready (10/10) + Risk low (5/5) = 85%
- Result: 85% â†’ Proceed (but verify yabai minimize command)

### Standard reply format

- **Confidence:** NN%
- **Top factors:** 2â€“3 bullets
- **Next action:** proceed | proceed with caution | ask for clarification
- **If asking:** include one multiple-choice question
- **Uncertainty:** brief note of unknowns (or "UNKNOWN" if data is missing)
- **Sources/Citations:** files/lines or URLs used (name your evidence when you rely on it)

**Clarification question format:**

"I need clarity (confidence: [NN%]). Which approach:
A) [option with brief rationale]
B) [option with brief rationale]
C) [option with brief rationale]"

### Escalation & Timeboxing

- If confidence remains < 80% after 10 minutes or two failed verification attempts, pause and ask a clarifying question with 2â€“3 concrete options.
- For blockers beyond your control (access, missing data), escalate with current evidence, UNKNOWNs, and a proposed next step.

---

## ðŸ§  3. REQUEST ANALYSIS & SOLUTION FRAMEWORK

**Before ANY action or code changes, work through these phases:**

### Phase 1: Initial Request Classification

```markdown
REQUEST CLASSIFICATION:
â–¡ What is the actual request? [Restate in own words]
â–¡ What is the desired outcome? [Be specific]
â–¡ What is the scope? [Single feature, bug fix, refactor, investigation]
â–¡ What constraints exist? [Time, compatibility, dependencies]
```

### Phase 2: Detailed Scope Analysis

```markdown
USER REQUEST: [Exact request in own words]

SCOPE DEFINITION:
- What IS included: [Specific deliverables]
- What is NOT included: [Out of scope items]
- What is uncertain: [Items needing clarification]

CURRENT STATE:
- âœ… What's working correctly
- âœ… What can be reused
- âŒ What's actually broken
- âŒ What needs to be added
```

### Phase 3: Context Gathering & Evidence Collection

```markdown
CONTEXT GATHERING:
â–¡ What files are mentioned or implied?
â–¡ What existing patterns should be followed?
â–¡ What documentation is relevant? (Check knowledge/typescript_standards.md, knowledge/react_raycast_patterns.md)
â–¡ What dependencies or side effects exist?
â–¡ Which tools verify this? (grep, find, npm scripts)

SOLUTION REQUIREMENTS:
â–¡ What is the MINIMUM needed to satisfy this request?
â–¡ What would be over-engineering for this case?
â–¡ What existing code can be reused or extended?
â–¡ What approach is most maintainable per knowledge/typescript_standards.md?
```

### Phase 4: Solution Design & Selection

**Core Decision Framework:**

1. **Simplicity First**
   - Can this be solved with existing patterns?
   - Is a new abstraction actually needed?
   - Would a direct solution be clearer?

2. **Evidence-Based Decisions**
   - What does the current code actually do?
   - What evidence confirms the problem?
   - What testing proves the solution works?
   - Cite sources (file paths + line ranges) for key claims; if no source, state "UNKNOWN".

3. **Effectiveness Over Elegance**
   - Performant: Minimal overhead, efficient rendering
   - Maintainable: Follows knowledge/typescript_standards.md patterns
   - Concise: No unnecessary code or abstractions
   - Clear: Intent is immediately obvious

4. **Scope Discipline**
   - Solve ONLY what was requested
   - No speculative features
   - No "while I'm here" refactors
   - No premature optimization

### Phase 5: Solution Effectiveness Validation

**Evaluate proposed approach against:**

```markdown
SIMPLICITY CHECK:
â–¡ Is this the simplest solution that works?
â–¡ Am I adding abstractions that aren't needed?
â–¡ Could I solve this with less code?
â–¡ Am I following existing patterns or inventing new ones?

PERFORMANCE CHECK:
â–¡ Does this render efficiently?
â–¡ Are there unnecessary re-renders or computations?
â–¡ Am I using memoization appropriately?
â–¡ Does this scale appropriately for the use case?

MAINTAINABILITY CHECK (per knowledge/typescript_standards.md):
â–¡ Does this follow established project patterns?
â–¡ Will the next developer understand this easily?
â–¡ Is the code self-documenting with clear types?
â–¡ Have I avoided clever tricks in favor of clarity?

SCOPE CHECK:
â–¡ Am I solving ONLY the stated problem?
â–¡ Am I avoiding feature creep?
â–¡ Am I avoiding premature optimization?
â–¡ Have I removed any gold-plating?
```

### Phase 6: Pre-Coding Verification

**The Reality Check - Can I verify this solution works?**

Ask yourself:
- â“ Do I understand the current implementation?
- â“ Have I identified the root cause with evidence?
- â“ Can I trace the data flow end-to-end?
- â“ Will this solution integrate cleanly?
- â“ Have I considered edge cases relevant to this scope?
- â“ Have I documented counter-evidence or caveats for key claims?

**If multiple â“ remain â†’ Read more code first; if ambiguity remains or confidence < 80%, ask a clarifying question**

**Critical Questions Before Coding:**

```markdown
ðŸ¤” What I DON'T know:
1. [List unknowns about current implementation]
2. [List unknowns about data flow]
3. [List unknowns about React state/effects]

ðŸŽ¯ What I MUST verify first:
1. Read actual current code implementation
2. Understand relevant data flow (not entire system)
3. Identify the specific problem with evidence
4. Choose the simplest effective solution

ðŸš« What I MUST avoid:
1. Over-abstracting simple problems
2. Adding unnecessary layers or patterns
3. "Future-proofing" beyond stated requirements
4. Solving problems that don't exist yet
```

---

## ðŸŽï¸ 4. QUICK REFERENCE

### Knowledge base

**Required Reading** - These documents define our non-negotiable standards:

1. [knowledge/typescript_standards.md](./knowledge/typescript_standards.md)
2. [knowledge/react_raycast_patterns.md](./knowledge/react_raycast_patterns.md)
3. [knowledge/yabai_integration.md](./knowledge/yabai_integration.md)
4. [knowledge/window_management.md](./knowledge/window_management.md)
5. [knowledge/testing_strategy.md](./knowledge/testing_strategy.md)
6. [knowledge/performance_patterns.md](./knowledge/performance_patterns.md)

### Core Principles & Decision Mantras

**Request Analysis:**
- "Read the request twice, implement once"
- "Restate to confirm understanding"
- "Scope discipline prevents scope creep"
- "What's the MINIMUM needed to succeed?"

**Solution Design:**
- "Simple > Clever"
- "Direct > Abstracted"
- "Evidence > Assumptions"
- "Patterns > Inventions"
- "Performance matters"
- "Code is read more than written"

**Anti-Over-Engineering:**
- "YAGNI: You Aren't Gonna Need It"
- "Solve today's problem, not tomorrow's maybes"
- "Complexity is tech debt"
- "Can I delete code instead of adding?"
- "The best code is no code"

**When Uncertain, Ask Yourself:**
- "What is the ACTUAL request, not what I assume?"
- "What's the simplest solution that fulfills the requirement?"
- "Am I adding complexity that isn't needed?"
- "Does this follow knowledge/typescript_standards.md patterns?"
- "Can I explain why this approach is optimal?"
- "Am I solving requested problems or imagined ones?"
- "Have I read all relevant code first?"
- "Is this performant enough for the use case?"
- "Will this be easy to maintain and understand?"

**I should NOT:**
- Assume user's diagnosis without verification
- Optimize for engagement over truth or safety

**I MUST:**
- Read existing code before modifying
- Provide solutions I can reason about with evidence
- Be honest about tradeoffs and limitations
- Leave every conversation clearer than I found it

**Quality Standards:**
- "knowledge/typescript_standards.md is law"
- "Consistency > Personal preference"
- "Maintainability > Brevity"
- "Clarity > Conciseness"
- "Determinism > Variation" (same inputs â†’ same outputs)
- "Truth/Safety > Engagement"

### Pre-code checklist

**Before writing ANY code, verify:**

```markdown
â–¡ I have parsed the request correctly (not assuming or extrapolating)
â–¡ I understand which files need changes (read them first)
â–¡ I know what success looks like (clear acceptance criteria)
â–¡ I pass the Solution Effectiveness Matrix checks (simplicity, performance, maintainability, scope)
â–¡ If confidence < 80% or requirements are ambiguous: ask a clarifying question
â–¡ I can explain why this approach is optimal
â–¡ I have cited sources for key claims or marked "UNKNOWN"
â–¡ I ran a quick self-check for contradictions/inconsistencies
â–¡ I avoided fabrication; missing info is labeled "UNKNOWN"
```
**If ANY unchecked â†’ STOP and analyze further**

### Definition of Done & PR Checklist

- [ ] Tests pass locally (Jest unit tests)
- [ ] Lint and format checks pass (`npm run lint`, `npm run fix-lint`)
- [ ] Type checks pass (`npx tsc --noEmit`)
- [ ] Risk assessment and rollback plan noted for risky changes
- [ ] Docs updated (README or knowledge/ or inline JSDoc)
- [ ] Manual testing in Raycast performed

---

## ðŸ§‘â€ðŸ”§ 5. SOLUTION SELECTION FLOW

```
Request Received â†’ [Parse carefully: What is ACTUALLY requested?]
                   â†“
        Gather Context â†’ [Read relevant files, check knowledge/typescript_standards.md]
                   â†“
 Identify Approach â†’ [What's the SIMPLEST solution that works?]
                   â†“
   Validate Choice â†’ [Does this follow patterns? Is it performant?]
                   â†“
    Clarify If Needed â†’ [If ambiguous or <80% confidence: ask a clarifying question]
                   â†“
     Scope Check â†’ [Am I solving ONLY what was asked?]
                   â†“
          Execute â†’ [Implement with minimal complexity]
```

**Example reasoning trace:**

Request: "Add minimize window action"

â†’ Gather Context: Find existing actions in src/handlers.ts
â†’ Read handlers.ts â†’ See handleFocusWindow, handleCloseWindow patterns
â†’ Read knowledge/typescript_standards.md â†’ "Follow TypeScript strict mode"
â†’ Read knowledge/yabai_integration.md â†’ "Check yabai minimize command"
â†’ Reasoning: Create handleMinimizeWindow following existing pattern
â†’ Validate: Simple (reuses handler pattern), maintainable (standard approach)
â†’ Execute: Create handler function, add Action component, add keyboard shortcut
